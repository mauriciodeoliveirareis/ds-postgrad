---
title: "PSI Week 10 Dimension Reduction"
output:
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: console
---
## Preliminaries
```{r}
needed_packages <- c("psych",   "REdaS", "Hmisc", "corrplot", "ggcorrplot", "factoextra",  "nFactors")                      
# Extract not installed packages
not_installed <- needed_packages[!(needed_packages %in% installed.packages()[ , "Package"])]    
# Install not installed packages
if(length(not_installed)) install.packages(not_installed, repos = "http://cran.us.r-project.org") 
library(psych)
library(REdaS)
library(Hmisc)
library(corrplot)
library(ggcorrplot)
library(factoextra)#Used for principal component analysis to get a different view of eigenvalues
library(nFactors)

# setwd as the folder where this script is in
current_path = rstudioapi::getActiveDocumentContext()$path
setwd(dirname(current_path))


#We are using a .dat file from Field, Miles and Field Discovering Statistics with R, a survey on fear of statistics - raq.dat
#load data
raqData<-read.delim("raq.dat", header = TRUE)

```

##Step 1: Screen the correlation matrix
```{r}
#create a correlation matrix (these are just some methods)
raqMatrix<-cor(raqData)
round(raqMatrix, 2)
Hmisc::rcorr(as.matrix(raqData))

```

###Using ggcorrplot
```{r }
#Using ggcorrplot. Note these are examples you need to choose a style for yourself, you do not need to create multiple correlation matrices
p.mat <- ggcorrplot::cor_pmat(raqData)
ggcorrplot::ggcorrplot(raqMatrix, title = "Correlation matrix for RAQ data")
#Showing Xs for non-significant correlations
ggcorrplot::ggcorrplot(raqMatrix, title = "Correlation matrix for RAQ data", p.mat = p.mat, sig.level = .05)
#Showing lower diagonal
ggcorrplot::ggcorrplot(raqMatrix, title = "Correlation matrix for RAQ data", p.mat = p.mat, sig.level = .05, type="lower")


#Overlay plot with a white grid to space things out.
#t1.cex is the text size, pch is controlling what is shown for non-significant correlations
ggcorrplot(raqMatrix, sig.level=0.05, lab_size = 4.5, p.mat = NULL,
           insig = c("pch", "blank"), pch = 1, pch.col = "black", pch.cex =1,
           tl.cex = 10) +
  theme(axis.text.x = element_text(margin=margin(-2,0,0,0)),
        axis.text.y = element_text(margin=margin(0,-2,0,0)),
        panel.grid.minor = element_line(size=10)) + 
  geom_tile(fill="white") +
  geom_tile(height=0.8, width=0.8)


#Showing the co-coefficients (this will be messy given the number of variables)
ggcorrplot::ggcorrplot(raqMatrix, lab=TRUE, title = "Correlation matrix for RAQ data",  type="lower")
```
###Using corrplot
```{r}
#Visualization of correlations using circles
#corrplot parameters method = c("circle", "square", "ellipse", "number", "shade",
#"color", "pie")
#type = c("full", "lower", "upper"),
corrplot::corrplot(raqMatrix, method="circle")
corrplot::corrplot(raqMatrix, method="circle", type="upper")
#Visualization using numbers
corrplot::corrplot(raqMatrix, method="number")

#Visualization of significance levels at 0.05
res1 <- corrplot::cor.mtest(raqMatrix, conf.level = .95)
corrplot::corrplot(raqMatrix, p.mat = res1$p, type="lower", sig.level = .05)

#Showing p-value for non-significant results
corrplot(raqMatrix, p.mat = res1$p, type="lower",insig = "p-value")
```




##Step 2: Check if data is suitable - look at the relevant Statistics
###Bartlett's test
```{r}
psych::cortest.bartlett(raqData)
psych::cortest.bartlett(raqMatrix, n=nrow(raqData))
```

###KMO
```{r}
#KMO (execute one of these):
REdaS::KMOS(raqData)
psych::KMO(raqData)
```

###Determinant
```{r}
#Determinant (execute one of these):
det(raqMatrix)
det(cor(raqData))
```
With a Determinant of 0.00052, 
##Step 3: Do the Dimension Reduction  (PRINCIPAL COMPONENTS ANALYSIS)

```{r}
#pcModel<-principal(dataframe/R-matrix, nfactors = number of factors, rotate = "method of rotation", scores = TRUE)

#On raw data using principal components analysis
#For PCA we know how many factors if is possible to find
#principal will work out our loadings of each variable onto each component, the proportion each component explained and the cumulative proportion of variance explained 
pc1 <-  principal(raqData, nfactors = 23, rotate = "none")
pc1 <-  principal(raqData, nfactors = length(raqData), rotate = "none")
pc1#output all details of the PCA
```

##Step 4: Decide which components to retain (PRINCIPAL COMPONENTS ANALYSIS)
```{r}
#Create the scree plot
plot(pc1$values, type = "b") 
#Print the variance explained by each component
pc1$Vaccounted 
#Print the Eigenvalues
pc1$values


#Another way to look at eigen values plus variance explained (need to use princomp function of PCA to get right class for use with factoextra functions)
pcf=princomp(raqData)
factoextra::get_eigenvalue(pcf)
factoextra::fviz_eig(pcf, addlabels = TRUE, ylim = c(0, 50))#Visualize the Eigenvalues
factoextra::fviz_pca_var(pcf, col.var = "black")
factoextra::fviz_pca_var(pcf, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE # Avoid text overlapping
             )

#Print the loadings above the level of 0.3
psych::print.psych(pc1, cut = 0.3, sort = TRUE)
#create a diagram showing the components and how the manifest variables load
fa.diagram(pc1) 
#Show the loadings of variables on to components
fa.sort(pc1$loading)
#Output the communalities of variables across components (will be one for PCA since all the variance is used)
pc1$communality 
#Visualize contribution of variables to each component
var <- factoextra::get_pca_var(pcf)
corrplot::corrplot(var$contrib, is.corr=FALSE) 

# Contributions of variables to PC1
factoextra::fviz_contrib(pcf, choice = "var", axes = 1, top = 10)
# Contributions of variables to PC2
factoextra::fviz_contrib(pcf, choice = "var", axes = 2, top = 10)
```

##Step 5: Apply rotation
```{r}
#Apply rotation to try to refine the component structure
pc2 <-  principal(raqData, nfactors = 4, rotate = "varimax")#Extracting 4 factors
#output the components
psych::print.psych(pc2, cut = 0.3, sort = TRUE)
#output the communalities
pc2$communality
#NOTE: you can do all the other things done for the model created in pc1

```
##Step 3: Do the dimension reduction and Step 4: Decide which factors/components to retain (FACTOR ANALYSIS)
```{r}
#Factor Analysis - the default here is principal axis factoring fm=pa
#If we know our data going in is normally distributed we use maximum likelihood
facsol <- psych::fa(raqMatrix, nfactors=4, obs=NA, n.iter=1, rotate="varimax", fm="pa")

#Create your scree plot
plot(facsol$values, type = "b") #scree plot

#Print the Variance accounted for by each factor/component
facsol$Vaccounted
#Output the Eigenvalues
facsol$values 

#Print the components with loadings
psych::print.psych(facsol,cut=0.3, sort=TRUE)

#Print sorted list of loadings
fa.sort(facsol$loading)

#create a diagram showing the factors and how the manifest variables load
fa.diagram(facsol)

#Note: you can apply rotation as you did for PCA

```
##Step 5: Apply rotation
```{r}
#Apply rotation to try to refine the component structure
facsolrot <-  principal(raqMatrix, rotate = "varimax")
#output the components
psych::print.psych(facsolrot, cut = 0.3, sort = TRUE)
#output the communalities
facsolrot$communality

```
##Step 6: Reliability Analysis
```{r}
#If you know that variables are grouped, test each group as a separate scale
computerFear<-raqData[,c(6, 7, 10, 13, 14, 15, 18)]
statisticsFear <- raqData[, c(1, 3, 4, 5, 12, 16, 20, 21)]
mathFear <- raqData[, c(8, 11, 17)]
peerEvaluation <- raqData[, c(2, 9, 19, 22, 23)]

#Output our Cronbach Alpha values
psych::alpha(computerFear)
#If some items are to be reversed keyed, then either recode or get alpha to reverse code as needed by setting check.keys=TRUE (be careful with this - make sure you know it makes sense)
psych::alpha(statisticsFear, check.keys=TRUE)

psych::alpha(mathFear)
psych::alpha(peerEvaluation)
psych::alpha(statisticsFear) #for illustrative proposes
```