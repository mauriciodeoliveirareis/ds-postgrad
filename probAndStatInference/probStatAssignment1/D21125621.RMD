---
title: "CA Task 1: Bike Sharing Dataset Data Set"
output:
  html_document: default
  pdf_document: default
---


**Student Number: D21125621**  
**Student Name: Mauricio de Oliveira Reis**  
**Programme Code: TU256/1**  
**Dataset Used: Bike Sharing Dataset Data Set**  
  
## 0. Preliminaries   
```{r, echo=FALSE, , message=FALSE, warning=FALSE, results='hide'}
# setwd as the folder where this script is in
current_path = rstudioapi::getActiveDocumentContext()$path
setwd(dirname(current_path))
```
```{r, echo=FALSE, , message=FALSE, warning=FALSE, results='hide'}
#Load and Install required packages 
install_packages <- function(pkg) { 
  
  # Install package if it is not already
  if (!(pkg %in% installed.packages()[, "Package"])){ 
    
    install.packages(pkg, repos='http://cran.us.r-project.org')
  }
  
  library(pkg, character.only = TRUE)
  
} # end installPackages()

#Create the list of packages we need
pkg_list = c("ggplot2", "dplyr", "gridExtra", "vtable", "kableExtra", "qqplotr", "psych", "car")
#Call our function passing it the list of packages
lapply(pkg_list, install_packages)


```
In this session is to understand the dataset that was loaded and identify if it needs some transformation:
```{r, echo=FALSE, , message=FALSE, warning=FALSE}
#load bike sharing dataset and check its head
bike_sharing <- read.csv("bikeSharingByDay.csv", header=T)
head(bike_sharing) %>% 
  kbl(caption = "Table 1: Fist lines of Bike Sharing Dataset") %>%
  kable_styling()
ncols <- ncol(bike_sharing)
nrows <- nrow(bike_sharing)
```
We can wee in Table 1 that cnt seems to be the sum of casual and registered columns which wasn't so clear on the dataset description and, as specified on the dataset description, everything on this dataset is represented by numbers either integers or doubles, except dteday. So, for the other columns, we need just to pay attention to NAs and impossible values like zeros where we can't possibly have a zero. For dteday we need to check for leading spaces and understand if it need to be converted to a specific datatype for analysis. Also important to mention that this dataset has `r ncols` columns and `r nrows` rows.

```{r, echo=FALSE, , message=FALSE, warning=FALSE}
#Check if there are NAs on the dataset
na_count <-sapply(bike_sharing, function(y) sum(length(which(is.na(y)))))
na_count <- data.frame(na_count)
na_count  %>% 
  kbl(caption = "Table 2: Quantity of NAs per column") %>%
  kable_styling()
```
As per Table 2, we don't have any NAs on this dataset.

```{r, echo=FALSE, , message=FALSE, warning=FALSE}
#summary Statistics
summary(bike_sharing) %>% 
  kbl(caption = "Table 3: Summary Statistics of Bike Sharing Dataset") %>%
  kable_styling()
```
Table 3 shows the summary statistics and reveals a problematic issue for the hum(humidity) column: it has zero values. We will need to treat those zero values as NAs and decide what to do with the NAs further on in the analysis.

```{r, echo=FALSE, , message=FALSE, warning=FALSE}
#transforming all hum values that are zero to NAs
bike_sharing[bike_sharing$hum == 0,]$hum <- NA
qtyOfNAsOnBikeSharing <- sum(is.na(bike_sharing$hum))
```
In the end, we had only `r qtyOfNAsOnBikeSharing` hum vallues that we transformed in NA.
  
  


## 1. Does the temperature (actual) impact the total number of bikes hired per day?  
Before hypothesis test it, let's first understand our variables involved.

#### Undestanding and checking for normality: temp (Daily temperature)
As per the dataset description this is Normalized temperature in Celsius normalized with the following formula:
$$normalizedTemp = \frac{(temp-temp_{min})}{(temp_{max}-temp_{min})} $$
Let's fist check the Daily temperature distribution and see if it's a normal distribution:
```{r, echo=FALSE, , message=FALSE, warning=FALSE}
histogram_with_mean_and_median <- function(df, attr, mainTxt, xTxt) {
  attrFromDf <- df[[attr]]
  gg <- ggplot(df, aes(attrFromDf))
  # Change xlabel and title 
  gg <- gg + labs(x=xTxt, title = mainTxt)
  gg <- gg + geom_histogram(colour="black", aes(y=..density.., fill=..count..))
  gg <- gg + scale_fill_gradient("Count", low="#DCDCDC", high="#7C7C7C")
  # add mean line
  meanOfAttr <- mean(attrFromDf, na.rm = TRUE)
  gg <- gg + geom_vline(aes(xintercept = meanOfAttr),col='red', size=1) 
  #add median line
  gg <- gg + geom_vline(aes(xintercept = median(attrFromDf, , na.rm = TRUE)),col='blue', size=1)
  gg <- gg + stat_function(fun=dnorm, color="red",args=list(mean=meanOfAttr,sd=sd(attrFromDf, na.rm = TRUE)))
  return (gg)
}


histogram_with_mean_and_median(bike_sharing,"temp", 
                          mainTxt = "Chart 1: Daily temperature distribution", xTxt = "Temperature (Normalized)")

```

  
```{r, echo=FALSE, , message=FALSE, warning=FALSE}
# Create a qqplot from temp
gg <- ggplot(data = bike_sharing, mapping = aes(sample = temp)) +
    stat_qq_band() +
    stat_qq_line() +
    stat_qq_point() +
    labs(x = "Theoretical Quantiles", y = "Sample Quantiles", title = "Chart 2: Daily temperature qqplot")
gg

```
  
As we can see in Chart 1, even though the mean(red) and the median(blue) are quite close, this distribution it's not easy to conclude if this distribution is clouse enough to a normal distribution. The Chart 2, the QQ-Plot shape suggests that the data is too peaked in the middle but a lot of data fall within the Theoretical Quantiles. With that, we better do some extra testa to see if the data is normal.

```{r, echo=FALSE, , message=FALSE, warning=FALSE}
apply_normality_tests <- function(dfColumn) {
  attrSkew<-semTools::skew(dfColumn)
  attrKurt<-semTools::kurtosis(dfColumn)
  skew <- attrSkew[1]/attrSkew[2]
  
  kurt <- attrKurt[1]/attrKurt[2]
  
  ztpAttr <- abs(scale(dfColumn))
  
  perc196 <- FSA::perc(as.numeric(ztpAttr), 1.96, "gt")
  perc329 <- FSA::perc(as.numeric(ztpAttr), 3.29, "gt")

  return (data.frame(
    skew = skew,
    kurt = kurt,
    perc196 = perc196,
    perc329 = perc329
  ))
}
tempNormalityTests <- apply_normality_tests(bike_sharing$temp)

```
Although Excess Kutosis for temp is at `r tempNormalityTests$kurt`, way below -2 threshold, after converting it to standardized scores, we noticed that less than 5% of the data falls outside of of -3.29/3.29 threshold (`r tempNormalityTests$perc196`% and `r tempNormalityTests$perc329`% respectively) and as this dataset has more than 80 rows, we can treat this data as normal-like.   

#### Undestanding and checking for normality: cnt (number of bikes hired per day)
  
As stated before, cnt (number of bikes hired per day) seems to be the sum of casual and registered users. Let's first confirm if that's the case to understand better our dataset and see how the proportions look like.

```{r, echo=FALSE, , message=FALSE, warning=FALSE}
#Check the amount of users for each type
casualAndRegisteredDf <- bike_sharing %>% select(casual, registered)
sumUserTypeDf<- data.frame(value=apply(casualAndRegisteredDf,2,sum))
sumUserTypeDf$key=rownames(sumUserTypeDf)
p <-ggplot(data=sumUserTypeDf, aes(x=key, y=value, fill=key)) +
geom_bar(colour="black", stat="identity", show.legend=FALSE) 
p + labs(title = "Chart 3: Quantity of casual and registered users", x="Type of user", y="Quantity")

```
```{r, echo=FALSE, , message=FALSE, warning=FALSE}
totalCasual <- sum(bike_sharing$casual)
totalRegistered <- sum(bike_sharing$registered)
total <- totalCasual + totalRegistered
percentCasual <- round(totalCasual * 100 / total, 2 )
percentRegistered <- round(totalRegistered * 100 / total, 2)
casualPlusRegistered = bike_sharing$casual + bike_sharing$registered
qtyRowsCntDiffUsers <-  sum(bike_sharing$cnt != casualPlusRegistered)

```

Chart 3 shows that we have way more registered users than casual ones, to be exact, we have `r percentCasual`% of users are casual and `r percentRegistered`% are registered.  
Also, we found `r qtyRowsCntDiffUsers` cases where the sum of casual and registered users are different, therefore, cnt is really the sum of those other two columns and "total rental bikes" is the same as "total users" in a day, this means that the dataset either doesn't consider when the same user rents more than one bike in a day or count of users have duplicates or no user ever rents more than one bike a day.
  
  
How each type of user distribution looks like? 
```{r, echo=FALSE, , message=FALSE, warning=FALSE}
#Check distribution of number of bikes hired per day 
p1 <- histogram_with_mean_and_median(bike_sharing, "casual", "Chart 4: Daily casual users distribution", "Casual users")
p2 <- histogram_with_mean_and_median(bike_sharing, "registered", "Chart 5: Daily registered users distribution", "Registered users")
p3 <- histogram_with_mean_and_median(bike_sharing,"cnt", "Chart 6: Daily total users/bikes distribution", "Users/bikes")
grid.arrange(p1, p2, p3, nrow = 3)

```
  
Daily casual users (Chart 4) is a right skewed distribution with mean and median a little bit far from one another and showing that is more common to have roughly 1000 users or less per day. Whereas registered users (Chart 5) is a little bit more normal looking and as expected given the high percentage of registered users, the combination distributions (Chart 6) is quite similar to the registered one.
From now on, as we already have an understanding of how our users/bikes hired per day are distributed, we will use only the ctn column and call it bikes hired per day.

```{r, echo=FALSE, , message=FALSE, warning=FALSE}
# Create a qqplot from temp
gg <- ggplot(data = bike_sharing, mapping = aes(sample = cnt)) +
    stat_qq_band() +
    stat_qq_line() +
    stat_qq_point() +
    labs(x = "Theoretical Quantiles", y = "Sample Quantiles", title = "Chart 7: Bikes hired per day qqplot")
gg

```
  
Although the QQ Plot (Chart 7) suggest a too centered in the middle shape, the majority of the datapoints fall very close to an ideal normal distribution curve. With that, we better do a few tests to check for normality.

```{r, echo=FALSE, , message=FALSE, warning=FALSE}
cntNormalityTests <- apply_normality_tests(bike_sharing$cnt)
```
Although Excess Kutosis for cnt is at `r cntNormalityTests$kurt`, below the -2 threshold, after converting it to standardized scores, we noticed that less than 5% of the data falls outside of of -3.29/3.29 threshold (`r cntNormalityTests$perc196`% and `r cntNormalityTests$perc329`% respectively) and as this dataset has more than 80 rows, we can treat this data as normal-like.   

#### Hypotesis Testing
Does the temperature (actual) impact the total number of bikes hired per day?  

- Null hypothesis $(H_0)$: Temperature (actual) doesn't impact the total number of bikes hired per day  
- Alternative hypothesis $H_\alpha$: Temperature (actual) impacts the total number of bikes hired per day  
- Significance level $\alpha$: 0.05  

```{r, echo=FALSE, , message=FALSE, warning=FALSE}
tempCntPearson <- stats::cor.test(bike_sharing$temp, bike_sharing$cnt, method='pearson')
tempCntCor <- tempCntPearson$estimate
tmpCntPvalue <- tempCntPearson$p.value
```
Since both distributions were considered normal, a person correlation test was conducted and it has shown a positive correlation of `r tempCntCor` and a p-value of `tmpCntPvalue`, which suggests strong significance level and it's way below our established significance level for this hypotesis testing ($\alpha = 0.05$), therefore, we can reject the null hypothesis and conclude that temperature impacts the total number of bikes hired per day.
  
  
 
## 2. Does the level of humidity impact the total number of bikes hired per day?
Before hypothesis test it, let's first understand this new variable introduced, humidity.

#### Undestanding and checking for normality: hum (humidity) 
This is a normalised value for humidity where values were divided by 100. As stated before, we've found just 1 zero value for humidity that we've transformed in NA and should not impact our analysis in this dataset with `r nrows` rows.

Let's fist check the humidity distribution and see if it's a normal distribution:
```{r, echo=FALSE, , message=FALSE, warning=FALSE}
histogram_with_mean_and_median(bike_sharing,"hum", 
                          mainTxt = "Chart 8: Daily humidity distribution", xTxt = "Humidity")
```

  
```{r, echo=FALSE, , message=FALSE, warning=FALSE}
# Create a qqplot from humidity
gg <- ggplot(data = bike_sharing, mapping = aes(sample = hum)) +
    stat_qq_band() +
    stat_qq_line() +
    stat_qq_point() +
    labs(x = "Theoretical Quantiles", y = "Sample Quantiles", title = "Chart 9: Daily humidity qqplot")
gg

```
  
As we can see in Chart 8, mean(red) and the median(blue) are quite close, and the distribution looks a lot like a normal distribution, also, in Chart 9, the QQ-Plot shape suggests that the data is somewhat peaked in the middle but a lot of data fall within the Theoretical Quantiles. The charts suggest that this can be treated as a normal distribution but we better also test its skewness and kutosis.

```{r, echo=FALSE, , message=FALSE, warning=FALSE}
humNormalityTests <- apply_normality_tests(bike_sharing$hum)
```
Although Excess Kutosis for humidity is at `r humNormalityTests$kurt`, slightly below -2 threshold, after converting it to standardized scores, we noticed that less than 5% of the data falls outside of of -3.29/3.29 threshold (`r humNormalityTests$perc196`% and `r humNormalityTests$perc329`% respectively) and, as this dataset has more than 80 rows, we can treat this data as normal-like.   

#### Hypotesis Testing
Does the level of humidity impact the total number of bikes hired per day?

- Null hypothesis $(H_0)$: The level of humidity doesn't impact the total number of bikes hired per day  
- Alternative hypothesis $H_\alpha$: The level of humidity impacts the total number of bikes hired per day  
- Significance level $\alpha$: 0.05  

```{r, echo=FALSE, , message=FALSE, warning=FALSE}
humCntPearson <- stats::cor.test(bike_sharing$hum, bike_sharing$cnt, method='pearson')
humCntCor <- humCntPearson$estimate
humCntPvalue <- humCntPearson$p.value
```
  
Since both distributions were considered normal, a person correlation test was conducted and it has shown a negative correlation of `r humCntCor` and a p-value of `r humCntPvalue`, which suggests strong significance level and it's below our established significance level for this hypotesis testing ($\alpha = 0.05$), therefore, we can reject the null hypothesis and conclude that level of humidity impacts the total number of bikes hired per day.
  
  
  
## 3. Does the total number of bikes hired per day vary according to whether a day is a regular weekday or a weekend?

#### Undestanding variable: workingday 
As per dataset description this variable contains the value 1 if it's not a weekend or holiday and 0 otherwise.

```{r, echo=FALSE, , message=FALSE, warning=FALSE}
psych::describeBy(bike_sharing$cnt, bike_sharing$workingday, mat=TRUE) %>% 
  kbl(caption = "Table 4: Descriptive statistics of bikes hired per Workingday") %>%
  kable_styling()
```
Table 4 shows that there are more than twice as much entries for a regular weekday, there is also some difference in the standard deviation and the mean of the bikes hired on each group which we will analise later on if it's significant.

```{r, echo=FALSE, , message=FALSE, warning=FALSE}
# changes workingday to a factor so we can apply the Levene Test
bike_sharing$workingday = as.factor(bike_sharing$workingday)
workingDayLervene <- car::leveneTest(cnt ~ workingday, data=bike_sharing)
workingDayLervenePvalue <- workingDayLervene$`Pr(>F)`[1]
```
A Levene Test was conducted to understand if the variance differences between the bikes hired per day in regular weekdays and not regular weekdays is statistically significant and, with a p-value of `r workingDayLervenePvalue`, we can conclude that this difference is statistically significant and we can treat those two groups as with unequal variances.

#### Hypotesis Testing
Does the total number of bikes hired per day vary according to whether a day is a regular weekday or a weekend?

- Null hypothesis $(H_0)$: Whether a day is a regular weekday or a weekend, it doesn't impact the total number of bikes hired per day  
- Alternative hypothesis $H_\alpha$: Whether a day is a regular weekday or a weekend, it impacts the total number of bikes hired per day  
- Significance level $\alpha$: 0.05  

```{r, echo=FALSE, , message=FALSE, warning=FALSE}
res <- stats::t.test(cnt~workingday,var.equal=FALSE,data=bike_sharing)

#there is non-significant differencee on the test above so I'll skip right away to the eta calculation
#Eta squared calculation
effes=round((res$statistic*res$statistic)/((res$statistic*res$statistic)+(res$parameter)),3)

```
An independent-samples t-test was conducted to compare bikes hired per day on regular weekday and bikes hired per day on weekends. No significant difference in the amount of bikes hired was found (M=4584.82, SD=1878.42 for number of bikes hired per day on regular weekday, M=4330.17, SD=2052.14 for number of bikes hired per day not on regular weekday), (t(`r res$parameter`)= `r round(res$statistic,3)`, p = `r round(res$p.value,2)`. A very small effect size was also indicted by the eta squared value (`r effes`). With that, we fail to reject the null hypothesis and conclude that whether a day is a regular weekday or a weekend, it doesn't impact the total number of bikes hired per day.  


## 4. Does the total number of bikes hired per day vary by the day of week?

#### Undestanding variable: weekday 
As per dataset description this variable contains the day of the week, the description doesn't specify which day is Sunday as it can be interpreted as the first or last day of the week depending on the culture so, we need to understand that first.

```{r, echo=FALSE, , message=FALSE, warning=FALSE}
# changes weekday to a factor so we can treat it as factor
bike_sharing$weekday = as.factor(bike_sharing$weekday)

bike_sharing %>% group_by(weekday,workingday) %>% summarise(count_days = n()) %>% arrange(weekday) %>% 
  kbl(caption = "Table 5: Count of workingdays per weekday") %>%
  kable_styling()
```

As we can see on Table 5, weekdays 0 and 6 are never working days and weekday 1 is, most of the time, a working day. With that we can assume that day 0 is a Sunday as it's a non working day followed by a day that's usually a working day and proceeded by a day that isn't a working day.

```{r, echo=FALSE, , message=FALSE, warning=FALSE}
psych::describeBy(bike_sharing$cnt, bike_sharing$weekday, mat=TRUE) %>% 
  kbl(caption = "Table 6: Descriptive statistics of bikes hired per weekday") %>%
  kable_styling()
```
  
Table 6 shows us that this dataset is evenly distributed by days of the week, we can also see a slightly increase in the average number of bikes hired as the week goes starting with Sunday at the lowest with 4228.83 bikes hired on average and peaking at Friday with 4690.29 bikes hired, the number already goes slightly down on Saturdays to 4550.54 bikes hired on average. The standard deviations seem quite close from one another but we need to test to see if they are homogenious.

```{r, echo=FALSE, , message=FALSE, warning=FALSE}
#Conduct Bartlett's test - the null hypothesis is that variances in groups are equal so to assume homogeneity we would expect probability to not be statistically significant.
weekdayBarlett <- stats::bartlett.test(cnt~ weekday, data=bike_sharing)
weekdayBarlettPvalue <- weekdayBarlett$p.value
```
A Bartlett's Test was conducted to understand if the variance differences between the bikes hired per day on each weekday are statistically significant and, with a p-value of `r weekdayBarlettPvalue`, we can conclude that this difference is not statistically significant and we can treat those groups as with equal variances when conducting our tests.

#### Hypotesis Testing
Does the total number of bikes hired per day vary by the day of week?

- Null hypothesis $(H_0)$: The total number of bikes hired per day doesn't vary by the day of week
- Alternative hypothesis $H_\alpha$: The total number of bikes hired per day varies by the day of week
- Significance level $\alpha$: 0.05  

```{r, echo=FALSE, , message=FALSE, warning=FALSE}
# Compute the analysis of variance using the oneway.test from the stats package- we set VAR.equal to be true because we have homogeneity
res <- stats::oneway.test(bike_sharing$cnt ~ bike_sharing$weekday, data = bike_sharing, var.equal = TRUE)

#Compute our Eta squared
effes=effectsize::effectsize(res)

#Store the relevant pieces of the output from ANOVA in variables to use for reporting
#Degrees of freedom
df1=res$parameter[1]
df2=res$parameter[2]
#F statistic
Fstat=round(res$statistic, 3)
#Pvalue
pval=round(res$p.value,2)
```
A one way ANOVA test was conducted to compare number of bikes hired per day and day of the week. No statistically significant difference in the scores for number of bikes hired per day and day of the week was found  (F(2, `r df1`, `r df2`) = `r round(res$statistic,2)`, p=`r pval`)
A small effect size was also indicated by the eta squared value (`r round(effes$Eta2,2)`).
With that, we failed to reject the null hypothesis and conclude that the total number of bikes hired per day doesn't vary by the day of week.  
  
  
## 5. Is weather situation related to the season?

#### Undestanding variable: weathersit(Weather situation) 
As per dataset description this is a categorical variable with numbers from 1 to 4 that mean the following weater situations:  
1: Clear, Few clouds, Partly cloudy, Partly cloudy  
2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist  
3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds  
4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog  

```{r, echo=FALSE, , message=FALSE, warning=FALSE}
# Tranforms weathersit in factor to facilitate its usage as it's a categorical variable
bike_sharing$weathersit <- as.factor(bike_sharing$weathersit)
#Barplot weather situation per day
ggplot(data = bike_sharing, aes(x = weathersit)) +
    geom_bar() +
    labs(x = "Weather Situation", title = "Chart 10: Quantity of days with each weather situation")
```
  
Chart 10 shows that we don't have any registered days with weather situation 4 and very few with 3. So the weather situation is mostly 1 or 2 with the mode being 1.




  
#### Undestanding variable: season
As per dataset description this is a categorical variable with numbers from 1 to 4 that mean the following seasons:   
1:winter  
2:spring  
3:summer  
4:fall

```{r, echo=FALSE, , message=FALSE, warning=FALSE}
# Tranforms season in factor to facilitate its usage as it's a categorical variable
bike_sharing$season <- as.factor(bike_sharing$season)
#Barplot weather situation per day
ggplot(data = bike_sharing, aes(x = season)) +
    geom_bar() +
    labs(x = "Season", , title = "Chart 11: Quantity of days for each season")
```
  
Chart 11 shows that we have roughly the same amount of days for each season on this dataset with the mode being 3(summer) by a very small difference.  
  

#### Hypotesis Testing
Is weather situation related to the season?

- Null hypothesis $(H_0)$: The weather situation is not related to the season
- Alternative hypothesis $H_\alpha$: The weather situation is related to the season
- Significance level $\alpha$: 0.05  

```{r, echo=FALSE, , message=FALSE, warning=FALSE}
#transforms xtabs into dataframe and rename rows and columns to show as table 
xtabsToDataframe <- function(aXtabs, rownamesParm, colnamesParm) {
  mytableDfMat <- as.data.frame.matrix(aXtabs)
  mytableDf <- data.frame(mytableDfMat, row.names = rownamesParm)
  colnames(mytableDf) <- colnamesParm
  return(mytableDf)
}

weatherNames = c("Weather 1","Weather 2","Weather 3")
seasonNames = c("Season 1","Season 2","Season 3","Season 4")
#Create your contingency table
mytable<-xtabs(~weathersit+season, data=bike_sharing)
xtabsToDataframe(mytable, weatherNames, seasonNames) %>% 
  kbl(caption = "Table 7: Days with a specific weather per season") %>%
  kable_styling()
#chi square test
#correct=TRUE to get Yates correction, this is needed because this table has cells with a count smaller than 5
ctest<-stats::chisq.test(mytable, correct=TRUE)
ctestDegreeFreedom <- ctest$parameter[[1]]

```

```{r, echo=FALSE, , message=FALSE, warning=FALSE}
xtabsToDataframe(ctest$expected, weatherNames, seasonNames) %>% #expected frequencies
  kbl(caption = "Table 8: Expected Frequencies") %>%
  kable_styling()
```

```{r, echo=FALSE, , message=FALSE, warning=FALSE}
xtabsToDataframe(ctest$observed, weatherNames, seasonNames) %>%#observed frequencies
  kbl(caption = "Table 9: Observed Frequencies") %>%
  kable_styling()  
#Using Cramer to access the effect size since this is a 3x4 contingency table, not a 2x2
creamerEffctSize <- round(sjstats::cramer(mytable),2)
```


As the contingency table (Table 7) has shown, a few cells were with a value less than 5 so, a Chi Square test was conducted utilizing Yates correction. In this test we've found a P value of `r ctest$p.value`, below our established $\alpha = 0.05$. Table 8 and 9 show the discrepancy between the expected and observed frequencies. We also used Cramer's test to calculate the effect size and, with `r ctestDegreeFreedom` degrees of freedom and a effect size of `r creamerEffctSize`, we discovered that there is a small effect size.
With that, we reject the null hypothesis and conclude that the weather situation is related to the season.
  



## 6. Summary
On this report we've looked at several factors that might influence the number of bikes hired per day and also looked if the weather situation is related to the season on this particular dataset.  

On the side of influencing the number of bikes hired, we've found that the day of the week and also whether it's a regular working day or not do not influence in the number of bikes hired. We've found that temperature and humidity influence the the total number of bikes hired, temperature has a positive correlation meaning that the warmer it's, more bikes will be hired and humidity has a negative correlation with number of bikes hired meaning that the less humidity, more bikes will be hired. Remembering that this report was limited to establish correlation and not causation, questions like whether less humidity really makes users hire more bikes or users just hire more bikes due to another factors that can be closely related to humidity like temperature, was out of the scope of this report.  

Looking if season is related to weather situation, we've found that this is true, season really affects the weather situation with a small effect size.